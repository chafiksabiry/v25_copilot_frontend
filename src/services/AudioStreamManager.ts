export class AudioStreamManager {
  private ws: WebSocket | null = null;
  private audioContext: AudioContext | null = null;
  private gainNode: GainNode | null = null;
  private currentCodec: string = 'PCMU'; // Codec d√©tect√© depuis le message start (PCMU ou PCMA)

  private isConnected: boolean = false;
  private onErrorCallback: ((error: Error) => void) | null = null;
  
  // Audio quality settings
  private readonly GAIN_VALUE = 0.55; // Gain optimis√© pour √©viter le feedback et la distorsion (55%)

  // Jitter buffer / queue (Float32Array chunks)
  private chunkQueue: Float32Array[] = [];
  private readonly START_THRESHOLD = 3; // combien de chunks accumuler avant de d√©marrer
  private readonly MAX_QUEUE = 200; // maximum chunks √† stocker (augment√© pour g√©rer les pics de trafic)
  private readonly CHUNKS_PER_ITERATION = 5; // Traiter plusieurs chunks par it√©ration pour √™tre plus rapide
  private readonly SAMPLE_RATE = 8000; // Telnyx envoie en 8kHz
  private playbackTime = 0; // temps (AudioContext.currentTime) planifi√© pour le prochain chunk
  private animationFrameId: number | null = null; // Pour requestAnimationFrame

  // s√©curit√©
  private isPlaying = false;
  private isStopping = false;
  private overflowLogCount = 0; // Compteur pour limiter les logs d'overflow

  constructor(onError?: (error: Error) => void) {
    this.onErrorCallback = onError || null;
  }

  // --- Connexion WebSocket ---
  async connect(streamUrl: string) {
    try {
      console.log('üé§ Connecting to audio stream:', streamUrl);
      // create ws
      this.ws = new WebSocket(streamUrl);
      this.ws.binaryType = 'arraybuffer'; // on s'attend √† des ArrayBuffers si envoy√©s bruts

      this.ws.onopen = () => {
        console.log('üé§ WebSocket connected for audio streaming');
        this.isConnected = true;
      };

      this.ws.onmessage = async (event) => {
        try {
          // Telnyx envoie g√©n√©ralement du JSON contenant base64 payload
          // mais parfois on peut recevoir directement ArrayBuffer. G√©rer les deux cas.
          if (typeof event.data === 'string') {
            const message = JSON.parse(event.data);
            this.handleMessage(message);
          } else {
            // si c'est d√©j√† un buffer binaire (rare), on le joue directement en supposant PCMU bytes
            const ab = event.data as ArrayBuffer;
            const u8 = new Uint8Array(ab);
            const float32 = this.convertFromPCMU(u8);
            this.enqueueChunk(float32);
          }
        } catch (err) {
          console.error('‚ùå Error processing ws message:', err);
          this.onErrorCallback?.(err as Error);
        }
      };

      this.ws.onclose = () => {
        console.log('üé§ Audio WebSocket closed');
        this.isConnected = false;
      };

      this.ws.onerror = (err) => {
        console.error('üé§ Audio WebSocket error', err);
        this.isConnected = false;
        this.onErrorCallback?.(new Error('Audio WebSocket error'));
      };
    } catch (error) {
      console.error('‚ùå Error setting up audio stream:', error);
      this.onErrorCallback?.(error as Error);
      throw error;
    }
  }

  // --- G√©rer messages JSON typiques de Telnyx ---
  private handleMessage(message: any) {
    if (!message || typeof message !== 'object') return;

    const ev = message.event;
    switch (ev) {
      case 'connected':
        console.log('üéß Connected to audio stream with config:', message.config);
        break;
      case 'start':
        console.log('‚ñ∂Ô∏è Stream started:', message.stream_id);
        // D√©tecter le codec depuis le message start et le stocker
        const mediaFormat = message.start?.media_format;
        if (mediaFormat) {
          const codec = mediaFormat.encoding || 'PCMU';
          const sampleRate = mediaFormat.sample_rate || 8000;
          console.log(`üéµ Stream codec: ${codec}, sample rate: ${sampleRate}Hz`);
          // Stocker le codec pour l'utiliser lors du d√©codage
          this.currentCodec = codec;
        }
        break;
      case 'media':
        // message.media.payload est base64
        if (message.media && message.media.payload) {
          // D√©tecter le codec depuis le message ou utiliser celui du start event
          const codec = message.media.format || this.currentCodec || 'PCMU';
          
          // Certains providers envoient `payload` base64; d'autres envoient hex/array ‚Äî ici on g√®re base64
          const base64 = message.media.payload;
          const u8 = this.base64ToUint8Array(base64);
          
          // Utiliser la fonction de d√©codage qui supporte PCMU et PCMA
          const float32 = this.convertFromG711(u8, codec);
          this.enqueueChunk(float32);
        }
        break;
      case 'stop':
        console.log('‚èπÔ∏è Stream stopped:', message.stream_id);
        this.stopAndClear();
        break;
      case 'error':
        console.error('üé§ Stream error:', message);
        this.onErrorCallback?.(new Error(message.payload?.detail || 'Stream error'));
        break;
      default:
        // ignore or treat other events
        break;
    }
  }

  // --- Utilitaires base64 -> Uint8Array ---
  private base64ToUint8Array(base64: string): Uint8Array {
    // atob pour convertir base64 en binaire string; ensuite map to bytes
    const binaryString = atob(base64);
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);
    return bytes;
  }

  // --- ¬µ-law (G.711) d√©codage correct ---
  // Retourne Int16 amplitude (-32768..32767)
  private decodeMuLawByte(muLawByte: number): number {
    // Standard ITU-T G.711 ¬µ-law decoding
    let mu = ~muLawByte & 0xff;
    const sign = (mu & 0x80) ? -1 : 1;
    const exponent = (mu >> 4) & 0x07;
    const mantissa = mu & 0x0f;
    let magnitude = ((mantissa << 3) + 0x84) << (exponent);
    // magnitude is biased; adjust as standard describes
    const sample = sign * (magnitude - 0x84);
    // clamp to Int16
    return sample < -32768 ? -32768 : sample > 32767 ? 32767 : sample;
  }

  // --- A-law (G.711) d√©codage correct ---
  // Retourne Int16 amplitude (-32768..32767)
  // PCMA est utilis√© en Europe, PCMU en Am√©rique du Nord
  private decodeALawByte(aLawByte: number): number {
    // Standard ITU-T G.711 A-law decoding
    aLawByte ^= 0x55; // Inverser les bits pairs/impairs
    const sign = (aLawByte & 0x80) ? -1 : 1;
    const exponent = (aLawByte >> 4) & 0x07;
    const mantissa = aLawByte & 0x0f;
    
    let sample: number;
    if (exponent === 0) {
      // Cas sp√©cial pour exponent = 0
      sample = (mantissa << 4) + 8;
    } else {
      sample = ((mantissa << 4) + 0x108) << (exponent - 1);
    }
    
    sample = sign * (sample - 0x84);
    // clamp to Int16
    return sample < -32768 ? -32768 : sample > 32767 ? 32767 : sample;
  }

  // Convertit Uint8Array PCMU/PCMA -> Float32Array (valeurs dans [-1, 1])
  // D√©tecte automatiquement le codec (PCMU = ¬µ-law, PCMA = A-law)
  private convertFromG711(audioData: Uint8Array, codec: string = 'PCMU'): Float32Array {
    const out = new Float32Array(audioData.length);
    const isPCMA = codec === 'PCMA' || codec === 'pcma';
    
    for (let i = 0; i < audioData.length; i++) {
      const s16 = isPCMA 
        ? this.decodeALawByte(audioData[i])
        : this.decodeMuLawByte(audioData[i]);
      out[i] = s16 / 32768; // normaliser √† [-1, 1]
    }
    return out;
  }

  // Alias pour compatibilit√© (ancien code)
  private convertFromPCMU(pcmuData: Uint8Array): Float32Array {
    return this.convertFromG711(pcmuData, 'PCMU');
  }

  // --- Queue / Jitter buffer management avec backpressure ---
  private enqueueChunk(float32: Float32Array) {
    // Safety: drop if stopping
    if (this.isStopping) return;

    // SYST√àME DE BACKPRESSURE : Si la queue est presque pleine, ne pas ajouter
    // Cela √©vite les overflows et force le traitement √† acc√©l√©rer
    if (this.chunkQueue.length >= this.MAX_QUEUE * 0.9) {
      // Queue presque pleine : forcer le traitement imm√©diat
      if (this.isPlaying) {
        // Le traitement est d√©j√† en cours, on drop ce chunk pour √©viter l'overflow
        this.overflowLogCount++;
        if (this.overflowLogCount % 50 === 0) {
          console.warn(`‚ö†Ô∏è Backpressure: dropped ${this.overflowLogCount} chunks (queue at ${this.chunkQueue.length}/${this.MAX_QUEUE})`);
        }
        return; // Ne pas ajouter ce chunk
      } else {
        // Le traitement n'est pas d√©marr√©, d√©marrer imm√©diatement
        this.ensureAudioContext();
        this.startProcessingQueue();
      }
    }

    this.chunkQueue.push(float32);

    // Drop oldest if overflow (seulement en dernier recours)
    if (this.chunkQueue.length > this.MAX_QUEUE) {
      const chunksToRemove = Math.min(20, this.chunkQueue.length - this.MAX_QUEUE + 10);
      for (let i = 0; i < chunksToRemove; i++) {
        this.chunkQueue.shift();
      }
      this.overflowLogCount += chunksToRemove;
      if (this.overflowLogCount % 50 === 0) {
        console.warn(`‚ö†Ô∏è chunkQueue overflow ‚Äî dropped ${this.overflowLogCount} chunks (queue size: ${this.chunkQueue.length})`);
      }
    }

    // Si on a assez de chunks pour d√©marrer ET qu'on n'est pas d√©j√† en train de jouer, d√©marrer
    if (!this.isPlaying && this.chunkQueue.length >= this.START_THRESHOLD) {
      this.ensureAudioContext();
      this.startProcessingQueue();
    }
  }

  // --- Assurer creation et √©tat AudioContext et nodes ---
  private ensureAudioContext() {
    if (!this.audioContext || this.audioContext.state === 'closed') {
      // Si le navigateur exige une interaction utilisateur pour d√©marrer audio,
      // l'appelant devra appeler resumeAudio() apr√®s un click.
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: this.SAMPLE_RATE
      });
      this.gainNode = this.audioContext.createGain();
      // Ajuster le gain pour √©quilibrer volume et feedback
      // Gain √† 55% pour r√©duire la distorsion et le feedback
      this.gainNode.gain.value = 0.55;
      this.gainNode.connect(this.audioContext.destination);
      this.playbackTime = this.audioContext.currentTime;
      console.log('üîä AudioContext initialis√© (sampleRate:', this.SAMPLE_RATE, ')');
    }
  }

  // M√©thode publique pour reprendre l'AudioContext apr√®s interaction utilisateur
  async resumeAudio() {
    try {
      if (!this.audioContext) this.ensureAudioContext();
      if (this.audioContext && this.audioContext.state === 'suspended') {
        await this.audioContext.resume();
        console.log('‚ñ∂Ô∏è AudioContext resumed by user gesture');
      }
    } catch (err) {
      console.warn('Failed to resume AudioContext:', err);
    }
  }

  // --- Scheduling & playback (lecture en flux planifi√©e) ---
  private startProcessingQueue() {
    if (!this.audioContext) this.ensureAudioContext();
    if (!this.audioContext) return;
    if (this.isPlaying) return;

    this.isPlaying = true;
    // Si playbackTime < currentTime on la remet un peu en avant
    if (this.playbackTime < this.audioContext.currentTime) {
      this.playbackTime = this.audioContext.currentTime + 0.05; // 50ms headroom
    }

    // Processer la queue en "batch" non-blocant : traiter plusieurs chunks par it√©ration
    const process = () => {
      if (!this.audioContext || this.isStopping) {
        this.isPlaying = false;
        this.animationFrameId = null;
        return;
      }
      
      if (this.chunkQueue.length === 0) {
        // pas de donn√©es -> on arr√™te la boucle de scheduling ; on remet isPlaying √† false
        this.isPlaying = false;
        this.animationFrameId = null;
        return;
      }

      // Traiter plusieurs chunks par it√©ration pour √™tre plus rapide
      // Limiter √† CHUNKS_PER_ITERATION pour √©viter les violations de performance
      let processedCount = 0;
      const startTime = performance.now(); // Mesurer le temps de traitement
      
      while (this.chunkQueue.length > 0 && processedCount < this.CHUNKS_PER_ITERATION) {
        const chunk = this.chunkQueue.shift();
        if (chunk) {
          this.scheduleChunk(chunk);
          processedCount++;
        }
        
        // Limite de s√©curit√© : ne pas traiter plus de 10ms par frame
        if (performance.now() - startTime > 10) {
          break;
        }
      }

      // Utiliser requestAnimationFrame pour un meilleur timing
      // mais avec une limite de temps pour √©viter les violations
      if (this.chunkQueue.length > 0) {
        this.animationFrameId = requestAnimationFrame(process);
      } else {
        this.isPlaying = false;
        this.animationFrameId = null;
      }
    };

    this.animationFrameId = requestAnimationFrame(process);
  }

  private scheduleChunk(float32: Float32Array) {
    if (!this.audioContext || !this.gainNode) return;

    // Cr√©er un AudioBuffer avec la longueur exacte
    const buffer = this.audioContext.createBuffer(1, float32.length, this.SAMPLE_RATE);
    buffer.getChannelData(0).set(float32);

    const src = this.audioContext.createBufferSource();
    src.buffer = buffer;
    src.connect(this.gainNode);

    // Assurer playbackTime minimal devant currentTime pour √©viter start in past
    const now = this.audioContext.currentTime;
    if (this.playbackTime < now + 0.02) { // 20ms de marge
      this.playbackTime = now + 0.02;
    }

    try {
      src.start(this.playbackTime);
    } catch (err) {
      // si start √©choue (start in the past), jouer imm√©diatement
      try {
        src.start();
        console.warn('‚ö†Ô∏è start failed with playbackTime, started immediately');
      } catch (e) {
        console.error('‚ùå Failed to start audio source', e);
      }
    }

    // Mettre √† jour playbackTime : dur√©e du buffer = N / sampleRate (en secondes)
    const duration = buffer.length / this.SAMPLE_RATE;
    this.playbackTime += duration;

    // Clean up node apr√®s lecture (optionnel)
    src.onended = () => {
      try { src.disconnect(); } catch (_) {}
    };
  }

  // --- Stop & clear (appel√© √† la fin ou sur stop event) ---
  private stopAndClear() {
    this.isStopping = true;
    
    // Annuler requestAnimationFrame si actif
    if (this.animationFrameId !== null) {
      cancelAnimationFrame(this.animationFrameId);
      this.animationFrameId = null;
    }
    
    // vider queue
    this.chunkQueue = [];
    this.isPlaying = false;
    this.playbackTime = 0;

    // close audioContext but keep reference nullified after close
    if (this.audioContext && this.audioContext.state !== 'closed') {
      this.audioContext.close().catch((e) => {
        console.warn('Error closing AudioContext', e);
      }).finally(() => {
        this.audioContext = null;
        this.gainNode = null;
      });
    } else {
      this.audioContext = null;
      this.gainNode = null;
    }

    // allow reconnect later
    this.isStopping = false;
  }

  // --- Disconnect complet (appel√© manuellement) ---
  disconnect() {
    console.log('üé§ Disconnecting audio stream');

    if (this.ws) {
      try { this.ws.close(); } catch (_) {}
      this.ws = null;
    }

    this.stopAndClear();

    this.isConnected = false;
  }

  isStreamConnected(): boolean {
    return this.isConnected;
  }

}
